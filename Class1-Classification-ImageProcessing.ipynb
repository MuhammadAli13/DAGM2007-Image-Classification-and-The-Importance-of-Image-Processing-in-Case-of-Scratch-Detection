{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1121 00:48:36.431343  1124 deprecation_wrapper.py:119] From C:\\Users\\oshim\\Documents\\Dagm\\my_library.py:6: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'my_library' from 'C:\\\\Users\\\\oshim\\\\Documents\\\\Dagm\\\\my_library.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "import pandas as pd\n",
    "import cv2 as cv \n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numpy.random import seed \n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras import backend as k \n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.backend import tensorflow_backend\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications import xception\n",
    "from keras.applications import resnet50\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Activation\n",
    "from keras.layers import merge, Input\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D,Dropout,BatchNormalization,Dense,MaxPooling2D,ZeroPadding2D\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "img_width, img_height = 224, 224\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from PIL import Image, ImageEnhance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models\n",
    "from keras import layers , optimizers\n",
    "from keras.layers import Input\n",
    "from keras.applications import models\n",
    "from keras.applications import VGG16\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model \n",
    "import my_library as ml\n",
    "from importlib import reload\n",
    "from keras.optimizers import Adam\n",
    "reload(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  3% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 50 image(s) found.\n",
      "Output directory set to problem1/train/bad/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D756358>: 100%|██| 50/50 [00:00<00:00, 136.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D785278>: 100%|██| 50/50 [00:00<00:00, 135.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D7710B8>: 100%|██| 50/50 [00:00<00:00, 164.91 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 50 image(s) found.\n",
      "Output directory set to problem1/test/bad/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D778F28>: 100%|██| 50/50 [00:00<00:00, 146.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D771E10>: 100%|██| 50/50 [00:00<00:00, 150.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D761FD0>: 100%|██| 50/50 [00:00<00:00, 145.32 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 50 image(s) found.\n",
      "Output directory set to problem1/val/bad/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D761470>: 100%|██| 50/50 [00:00<00:00, 160.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D778B38>: 100%|██| 50/50 [00:00<00:00, 152.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=L size=512x512 at 0x1749D744128>: 100%|██| 50/50 [00:00<00:00, 156.18 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_good image number:  334\n",
      "train_bad image number:  200\n",
      "test_good image number:  333\n",
      "train_bad image number:  200\n",
      "val_good image number:  332\n",
      "val_bad image number:  200\n"
     ]
    }
   ],
   "source": [
    "ml.train_test_val_generator(num=1)\n",
    "#it will create train,test and val folder including \n",
    "# good and bad folder in each of them\n",
    "# num = 1 means dataset 1 (Class1 and Class1_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xTrain,xVal,xTest with out processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing_function(img):\n",
    "    edges = cv.Canny(img,50,100)\n",
    "    return cv.merge((edges,edges,edges))\n",
    "## this image processing function is actually useful only for class1 dataset.\n",
    "## for every classes there are different image processing functions.\n",
    "xTrain_,yTrain_,xVal_,yVal_,xTest_,yTest_ = ml.xTrain_xVal_xTest_from_train_test_val_folders(num=1,image_processing=False,size=224,\n",
    "                                                                                      image_processing_function=image_processing_function)\n",
    "# function name says it all. \n",
    "# by the way, it is worth mentioning that as total number of images is very\n",
    "# small, I did not use any generator. \n",
    "# xTrain is a pure numpy array of shape (534, 224, 224, 3)\n",
    "# xTrain,xVal,xTest are without any kind of image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xTrain,xVal,xTest with processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing_function(img):\n",
    "    edges = cv.Canny(img,50,100)\n",
    "    return cv.merge((edges,edges,edges))\n",
    "## this image processing function is actually useful only for class1 dataset.\n",
    "## for every classes there are different image processing functions.\n",
    "xTrain,yTrain,xVal,yVal,xTest,yTest = ml.xTrain_xVal_xTest_from_train_test_val_folders(num=1,image_processing=True,size=224,\n",
    "                                                                                      image_processing_function=image_processing_function)\n",
    "# function name says it all. \n",
    "# by the way, it is worth mentioning that as total number of images is very\n",
    "# small, I did not use any generator. \n",
    "# xTrain is a pure numpy array of shape (534, 224, 224, 3)\n",
    "# xTrain,xVal,xTest are with image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 with out Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 00:14:16.393141 11856 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1121 00:14:16.443818 11856 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1121 00:14:16.458313 11856 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1121 00:14:16.499046 11856 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1121 00:14:19.621487 11856 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1121 00:14:27.159524 11856 deprecation.py:506] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1121 00:14:27.159524 11856 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1121 00:14:27.235256 11856 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1121 00:14:27.371890 11856 deprecation.py:323] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534 samples, validate on 532 samples\n",
      "Epoch 1/7\n",
      " - 26s - loss: 0.9219 - acc: 0.5000 - val_loss: 0.6742 - val_acc: 0.6241\n",
      "Epoch 2/7\n",
      " - 10s - loss: 0.6947 - acc: 0.6011 - val_loss: 0.6566 - val_acc: 0.6241\n",
      "Epoch 3/7\n",
      " - 10s - loss: 0.6658 - acc: 0.6067 - val_loss: 0.6584 - val_acc: 0.6241\n",
      "Epoch 4/7\n",
      " - 10s - loss: 0.6692 - acc: 0.6142 - val_loss: 0.6511 - val_acc: 0.6241\n",
      "Epoch 5/7\n",
      " - 10s - loss: 0.6529 - acc: 0.6311 - val_loss: 0.6529 - val_acc: 0.6241\n",
      "Epoch 6/7\n",
      " - 10s - loss: 0.6519 - acc: 0.6479 - val_loss: 0.6451 - val_acc: 0.6447\n",
      "Epoch 7/7\n",
      " - 10s - loss: 0.6325 - acc: 0.6367 - val_loss: 0.6434 - val_acc: 0.6598\n"
     ]
    }
   ],
   "source": [
    "image_input= Input(shape=(224,224,3))\n",
    "model=VGG16(input_tensor=image_input, include_top=True, weights='imagenet')\n",
    "last_layer = model.get_layer('flatten').output\n",
    "last_layer = Dense(256, activation='relu',name='second_last')(last_layer)\n",
    "last_layer = Dropout(.8,name='drop')(last_layer)\n",
    "out = Dense(2, activation='softmax', name='output')(last_layer)\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "#custom_vgg_model.summary()\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-8]:\n",
    "\tlayer.trainable = False\n",
    "#custom_vgg_model.layers[-4].trainable\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min')\n",
    "checkpoint = ModelCheckpoint('class1_vgg_layers_8.hdf5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "batch_size = 32\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
    "hist = custom_vgg_model.fit(xTrain_, yTrain_, batch_size=batch_size, epochs=7, verbose=2, validation_data=(xVal_,yVal_),\n",
    "                            callbacks=[early_stopping,checkpoint],class_weight='balanced') ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 00:16:44.236085 11856 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Best Validation:\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 86 114]\n",
      " [ 69 264]]\n",
      "\n",
      "Confusion Matrix (as Percentage)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad data detection probability:  0.43\n",
      "Good data detection probability: 0.7927927927927928\n",
      "F1 score 0.7426160337552742\n"
     ]
    }
   ],
   "source": [
    "bestModel=load_model('class1_vgg_layers_8.hdf5')\n",
    "#bestModel=load_model('class6_vgg_layers_8.hdf5')\n",
    "print('\\nEvaluation on Best Validation:')\n",
    "#print('Accuracy: ',bestModel.evaluate(xTest_,yTest_)[1])\n",
    "\n",
    "preds=bestModel.predict(xTest_)\n",
    "predicted_class = []\n",
    "for i in preds:\n",
    "    if i[0]>i[1]:\n",
    "        predicted_class.append(0)\n",
    "    else:\n",
    "        predicted_class.append(1)\n",
    "f1,cm=ml.f1ScoreAndConfusionMatrix(ml.OneHotEncodeDecoder(yTest_),predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Obviously It will be better if I tune parameters. But I am more interested to see how it works in case of other models and in case of using image processing.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 with Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 00:09:34.153430  5164 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534 samples, validate on 532 samples\n",
      "Epoch 1/7\n",
      " - 16s - loss: 0.7463 - acc: 0.6330 - val_loss: 0.2743 - val_acc: 0.9511\n",
      "Epoch 2/7\n",
      " - 11s - loss: 0.1325 - acc: 0.9700 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 3/7\n",
      " - 11s - loss: 0.0140 - acc: 1.0000 - val_loss: 9.8334e-04 - val_acc: 1.0000\n",
      "Epoch 4/7\n",
      " - 12s - loss: 0.0034 - acc: 1.0000 - val_loss: 1.6780e-04 - val_acc: 1.0000\n",
      "Epoch 5/7\n",
      " - 11s - loss: 9.1343e-04 - acc: 1.0000 - val_loss: 2.2173e-05 - val_acc: 1.0000\n",
      "Epoch 6/7\n",
      " - 12s - loss: 4.0299e-04 - acc: 1.0000 - val_loss: 8.6124e-06 - val_acc: 1.0000\n",
      "Epoch 7/7\n",
      " - 12s - loss: 6.0808e-04 - acc: 1.0000 - val_loss: 3.1922e-06 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "image_input= Input(shape=(224,224,3))\n",
    "model=VGG16(input_tensor=image_input, include_top=True, weights='imagenet')\n",
    "last_layer = model.get_layer('flatten').output\n",
    "last_layer = Dense(256, activation='relu',name='second_last')(last_layer)\n",
    "last_layer = Dropout(.8,name='drop')(last_layer)\n",
    "out = Dense(2, activation='softmax', name='output')(last_layer)\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "#custom_vgg_model.summary()\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-8]:\n",
    "\tlayer.trainable = False\n",
    "#custom_vgg_model.layers[-4].trainable\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min')\n",
    "checkpoint = ModelCheckpoint('class1_vgg_layers_8.hdf5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "batch_size = 32\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
    "hist = custom_vgg_model.fit(xTrain, yTrain, batch_size=batch_size, epochs=7, verbose=2, validation_data=(xVal,yVal),\n",
    "                            callbacks=[early_stopping,checkpoint],class_weight='balanced') ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 00:12:33.075455  5164 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Best Validation:\n",
      "\n",
      "Confusion Matrix:\n",
      " [[200   0]\n",
      " [  0 333]]\n",
      "\n",
      "Confusion Matrix (as Percentage)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad data detection probability:  1.0\n",
      "Good data detection probability: 1.0\n",
      "F1 score 1.0\n"
     ]
    }
   ],
   "source": [
    "bestModel=load_model('class1_vgg_layers_8.hdf5')\n",
    "#bestModel=load_model('class6_vgg_layers_8.hdf5')\n",
    "print('\\nEvaluation on Best Validation:')\n",
    "#print('Accuracy: ',bestModel.evaluate(xTest_,yTest_)[1])\n",
    "\n",
    "preds=bestModel.predict(xTest)\n",
    "predicted_class = []\n",
    "for i in preds:\n",
    "    if i[0]>i[1]:\n",
    "        predicted_class.append(0)\n",
    "    else:\n",
    "        predicted_class.append(1)\n",
    "f1,cm=ml.f1ScoreAndConfusionMatrix(ml.OneHotEncodeDecoder(yTest),predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception without Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 00:25:47.392513 10428 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1121 00:25:47.444449 10428 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1121 00:25:47.460612 10428 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1121 00:25:47.498578 10428 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1121 00:25:53.537695 10428 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1121 00:25:53.927480 10428 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1121 00:26:01.654664 10428 deprecation.py:506] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1121 00:26:04.905294 10428 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1121 00:26:05.109728 10428 deprecation.py:323] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534 samples, validate on 532 samples\n",
      "Epoch 1/7\n",
      " - 47s - loss: 1.7746 - acc: 0.6142 - val_loss: 0.8293 - val_acc: 0.6447\n",
      "Epoch 2/7\n",
      " - 29s - loss: 0.6876 - acc: 0.6442 - val_loss: 8.4654 - val_acc: 0.4680\n",
      "Epoch 3/7\n",
      " - 28s - loss: 0.5925 - acc: 0.8352 - val_loss: 0.4179 - val_acc: 0.9774\n",
      "Epoch 4/7\n",
      " - 28s - loss: 0.2730 - acc: 0.9644 - val_loss: 0.2319 - val_acc: 0.9774\n",
      "Epoch 5/7\n",
      " - 29s - loss: 0.4012 - acc: 0.9532 - val_loss: 1.5089 - val_acc: 0.8778\n",
      "Epoch 6/7\n",
      " - 28s - loss: 0.1477 - acc: 0.9850 - val_loss: 0.1465 - val_acc: 0.9643\n",
      "Epoch 7/7\n",
      " - 28s - loss: 0.2396 - acc: 0.9757 - val_loss: 0.5241 - val_acc: 0.9568\n"
     ]
    }
   ],
   "source": [
    "conv_base = xception.Xception(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224,224, 3))\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "xTrain = xTrain/255\n",
    "xVal = xVal/255\n",
    "xTest = xTest/255\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='min')\n",
    "checkpoint = ModelCheckpoint('class1_p.hdf5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "batch_size = 8\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "hist_processed = model.fit(xTrain_, yTrain_, batch_size=batch_size, epochs=7, verbose=2, validation_data=(xVal_,yVal_),\n",
    "                            callbacks=[early_stopping,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 00:49:13.245835  1124 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1121 00:49:13.346047  1124 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1121 00:49:13.382099  1124 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1121 00:49:13.433672  1124 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1121 00:49:19.320756  1124 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1121 00:49:19.706497  1124 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1121 00:49:29.484695  1124 deprecation.py:506] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1121 00:49:32.497592  1124 deprecation_wrapper.py:119] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1121 00:49:32.670805  1124 deprecation.py:323] From C:\\Users\\oshim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534 samples, validate on 532 samples\n",
      "Epoch 1/7\n",
      " - 44s - loss: 1.8170 - acc: 0.6217 - val_loss: 6.0309 - val_acc: 0.6241\n",
      "Epoch 2/7\n",
      " - 29s - loss: 0.2490 - acc: 0.9551 - val_loss: 10.0587 - val_acc: 0.3759\n",
      "Epoch 3/7\n",
      " - 29s - loss: 0.5517 - acc: 0.9457 - val_loss: 10.0587 - val_acc: 0.3759\n",
      "Epoch 4/7\n",
      " - 29s - loss: 0.0904 - acc: 0.9925 - val_loss: 2.1957 - val_acc: 0.7350\n",
      "Epoch 5/7\n",
      " - 29s - loss: 0.2947 - acc: 0.9644 - val_loss: 10.0587 - val_acc: 0.3759\n",
      "Epoch 6/7\n",
      " - 29s - loss: 0.3368 - acc: 0.9682 - val_loss: 0.3878 - val_acc: 0.9643\n",
      "Epoch 7/7\n",
      " - 29s - loss: 0.2693 - acc: 0.9700 - val_loss: 1.0949 - val_acc: 0.7989\n"
     ]
    }
   ],
   "source": [
    "conv_base = xception.Xception(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224,224, 3))\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "xTrain = xTrain/255\n",
    "xVal = xVal/255\n",
    "xTest = xTest/255\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='min')\n",
    "checkpoint = ModelCheckpoint('xception_with_processing.hdf5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "batch_size = 8\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "hist_processed = model.fit(xTrain, yTrain, batch_size=batch_size, epochs=7, verbose=2, validation_data=(xVal,yVal),\n",
    "                            callbacks=[early_stopping,checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*something is definitely wrong. I will find out later*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
